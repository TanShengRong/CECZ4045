{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ass2_q1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6_Z6Mrst7xY",
        "outputId": "ae879614-028a-4dd4-9084-496b32d3ddae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srWCp3saWnHs",
        "outputId": "0d75d9c9-db75-4844-b10b-f837932e3cba"
      },
      "source": [
        "!ls \"gdrive/MyDrive/wikitext-2\" # check that it has successfully connected\n",
        "# files should be at ur GDrive inside folder wikitext-2\n",
        "!cp \"gdrive/MyDrive/wikitext-2/wiki.test.tokens.txt\" \"test.txt\" # copy the files to colab runtime\n",
        "!cp \"gdrive/MyDrive/wikitext-2/wiki.train.tokens.txt\" \"train.txt\"\n",
        "!cp \"gdrive/MyDrive/wikitext-2/wiki.valid.tokens.txt\" \"valid.txt\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wiki.test.tokens      wiki.train.tokens      wiki.valid.tokens\n",
            "wiki.test.tokens.txt  wiki.train.tokens.txt  wiki.valid.tokens.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDH_IyLyasQC"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JSW06aZavxI"
      },
      "source": [
        "import os\n",
        "from io import open\n",
        "import torch\n",
        "\n",
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = []\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "\n",
        "class Corpus(object):\n",
        "    def __init__(self, path):\n",
        "        self.dictionary = Dictionary()\n",
        "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
        "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
        "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
        "\n",
        "    def tokenize(self, path):\n",
        "        \"\"\"Tokenizes a text file.\"\"\"\n",
        "        assert os.path.exists(path)\n",
        "        # Add words to the dictionary\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            for line in f:\n",
        "                # remove the headers e.g.  = = Description = = \n",
        "                if line.startswith('='): \n",
        "                    continue\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word.lower()) # make to lower\n",
        "\n",
        "        # Tokenize file content\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            idss = []\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                ids = []\n",
        "                for word in words:\n",
        "                    ids.append(self.dictionary.word2idx[word.lower()]) # make to lower\n",
        "                idss.append(torch.tensor(ids).type(torch.int64))\n",
        "            ids = torch.cat(idss)\n",
        "\n",
        "        return ids\n",
        "    \n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.dictionary.idx2word)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BY-5KRizwDS"
      },
      "source": [
        "# Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BujxiynKzz7V"
      },
      "source": [
        "#=== params\n",
        "corpus = Corpus('/content')\n",
        "n_class = corpus.vocab_size\n",
        "n_step = 7 # n-1 in paper\n",
        "n_hidden = 200 # h in paper\n",
        "embed_size = 200       # m in paper\n",
        "batch_size = 1000\n",
        "order = n_step # order (int): the order of the language model, i.e. length of the history\n",
        "epochs = 100\n",
        "learning_rate = 0.001\n",
        "cuda = torch.cuda.is_available()\n",
        "seed = 42\n",
        "clip = 2.0\n",
        "#==="
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCn0n7sLb7uU"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf6-SXVscAqs"
      },
      "source": [
        "#== MODEL ==#\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "'''\n",
        "    the neural model learns the distributed representation of each word \n",
        "    (embedding matrix C) and \n",
        "    the probability function of a word sequence as a function of their distributed representations. \n",
        "    It has a hidden layer with \n",
        "    tanh activation and the output layer is a \n",
        "    Softmax layer. \n",
        "    The output of the model for each \n",
        "    input of (n - 1) previous words are the \n",
        "    probabilities over the |V | words in the vocabulary for the next word.\n",
        "'''\n",
        "class FNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, context_size, no_hidden, dropout=0.5):\n",
        "        super(FNNModel,self).__init__()\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            n_class (int): no. of vocabulary\n",
        "            m (int): size of each embedding vector\n",
        "#n-gram models construct tables of conditional probabilities for the next word, \n",
        "#for each one of a large number of contexts, i.e. combinations of the last n − 1 words\n",
        "            n_step (int): n-1 in paper. #n_step + 1 = n-gram. if n_step = 1, bigram\n",
        "            n_hidden (int): no. of hidden units associated with each word\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        Vars:\n",
        "            C: encoder (|V| x m)\n",
        "            H: hiden layer weight (n x (n-1)m)\n",
        "            W: word feature to output weights (|V| x (n-1)m)\n",
        "            d: hidden layer bias (has h no. of elements)\n",
        "            U: hidden-to-output weights (|V| × h matrix)\n",
        "            b: output bias (has |V| no. of elements)\n",
        "        \"\"\"\n",
        "        self.embeddings = nn.Embedding(vocab_size, embed_size)\n",
        "        self.linear1 = nn.Linear(context_size * embed_size, no_hidden)\n",
        "        self.linear2 = nn.Linear(no_hidden, vocab_size)\n",
        "        self.context_size = context_size\n",
        "        self.embed_size = embed_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        embeds = self.embeddings(inputs).view((-1, self.context_size * self.embed_size))\n",
        "        hidden_output = self.linear1(embeds)\n",
        "        # hidden_output = self.dropout(hidden_output)\n",
        "        out = hidden_output.tanh()\n",
        "        # out = self.dropout(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.dropout(out)\n",
        "        log_probs = F.log_softmax(out, dim=1) # [1000, 28912]: softmax on 28912's dim\n",
        "        return log_probs"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZez81nOa5Iv"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXNNicaihZe5"
      },
      "source": [
        "def batchify(data, batch_size):\n",
        "    # Work out how cleanly we can divide the dataset into args.batch_size parts.\n",
        "    nbatch = data.size(0) // batch_size\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * batch_size)\n",
        "    # Evenly divide the data across the batch_size batches.\n",
        "    data = data.view(batch_size, -1).t().contiguous()\n",
        "    return data\n",
        "def get_batch(data, i, order):\n",
        "    x = torch.autograd.Variable(torch.t(data[i:i+order]))\n",
        "    y = torch.autograd.Variable(data[i+order].view(-1))\n",
        "    return x, y\n",
        "def evaluate(data, model, criterion):\n",
        "\tmodel.eval()\n",
        "\ttotal_loss = 0\n",
        "\tn_steps = data.size(0) - order - 1\n",
        "\tfor i in tqdm(range(n_steps)):\n",
        "\t\tx, y = get_batch(data, i, order)\n",
        "\t\tout = model(x)\n",
        "\t\tloss = criterion(out, y)\n",
        "\t\ttotal_loss += loss.data.data\n",
        "\treturn total_loss / n_steps"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zavgNg0tklRG"
      },
      "source": [
        "def clock_time(s):\n",
        "    h, s = divmod(s, 3600)\n",
        "    m, s = divmod(s, 60)\n",
        "    return int(h), int(m), int(s)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztusWxUma4mg",
        "outputId": "018a82d4-67ca-4a0f-9c6c-7146cd1cf88f"
      },
      "source": [
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "\n",
        "train_data = batchify(corpus.train, batch_size)\n",
        "val_data = batchify(corpus.valid, batch_size)\n",
        "test_data = batchify(corpus.test, batch_size)\n",
        "if cuda:\n",
        "\ttrain_data, val_data, test_data = train_data.cuda(), val_data.cuda(), test_data.cuda()\n",
        "print('Using cuda: {}'.format(cuda))\n",
        "print('Size of training set: {:,} tokens'.format(np.prod(train_data.size())))\n",
        "print('Size of validation set: {:,} tokens'.format(np.prod(val_data.size())))\n",
        "print('Size of test set: {:,} tokens'.format(np.prod(test_data.size())))\n",
        "print('Vocabulary size: {:,}'.format(corpus.vocab_size))\n",
        "print('Example data:')\n",
        "for k in range(100, 107):\n",
        "    x = [corpus.dictionary.idx2word[i] for i in train_data[k:order+k, 0]]\n",
        "    y = [corpus.dictionary.idx2word[train_data[k+order, 0]]]\n",
        "    print(x, y)\n",
        "#=== initialise model\n",
        "model = FNNModel(\n",
        "    n_class, \n",
        "    embed_size, \n",
        "    n_step, \n",
        "    n_hidden)\n",
        "if cuda:\n",
        "  model.cuda()\n",
        "# Display the model's architecture\n",
        "print('Model: \\n', model)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.RMSprop(model.parameters(),lr=learning_rate)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda: True\n",
            "Size of training set: 2,088,000 tokens\n",
            "Size of validation set: 217,000 tokens\n",
            "Size of test set: 245,000 tokens\n",
            "Vocabulary size: 28,912\n",
            "Example data:\n",
            "['\"', 'nameless', '\"', ',', 'a', 'penal', 'military'] ['unit']\n",
            "['nameless', '\"', ',', 'a', 'penal', 'military', 'unit'] ['serving']\n",
            "['\"', ',', 'a', 'penal', 'military', 'unit', 'serving'] ['the']\n",
            "[',', 'a', 'penal', 'military', 'unit', 'serving', 'the'] ['nation']\n",
            "['a', 'penal', 'military', 'unit', 'serving', 'the', 'nation'] ['of']\n",
            "['penal', 'military', 'unit', 'serving', 'the', 'nation', 'of'] ['gallia']\n",
            "['military', 'unit', 'serving', 'the', 'nation', 'of', 'gallia'] ['during']\n",
            "Model: \n",
            " FNNModel(\n",
            "  (embeddings): Embedding(28912, 200)\n",
            "  (linear1): Linear(in_features=1400, out_features=200, bias=True)\n",
            "  (linear2): Linear(in_features=200, out_features=28912, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4bxaGvDZwK5",
        "outputId": "3d55b919-3765-412d-b85b-49f90bc96d02"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Nov 26 14:27:44 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    28W /  70W |   1035MiB / 15079MiB |      2%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArPR9kzyblhd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35936077-d358-4f05-fae4-6646314f121f"
      },
      "source": [
        "# Set seed for reproducibility.\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "parameters = [param for param in model.parameters() if param.requires_grad]\n",
        "# Training\n",
        "print('Training...')\n",
        "losses = dict(train=[], val=[])\n",
        "\n",
        "# initialize the early_stopping counter\n",
        "stop_counter = 0\n",
        "\n",
        "lr = learning_rate # so that can alter later if SGD not descending \n",
        "best_val_loss = None\n",
        "\n",
        "num_steps = train_data.size(0) - order - 1\n",
        "batch_order = np.arange(num_steps)\n",
        "\n",
        "t0 = time.time()\n",
        "try:\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        epoch_start_time = time.time()\n",
        "        np.random.shuffle(batch_order)\n",
        "\n",
        "        for step in range(1, num_steps+1):\n",
        "            idx = batch_order[step-1]\n",
        "            x, y = get_batch(train_data, idx, order)\n",
        "\n",
        "            model.zero_grad()\n",
        "            # Forward pass\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            debug = False\n",
        "            #   if debug:\n",
        "            #     # Debugging softmax approximation.\n",
        "            #     xe = nn.CrossEntropyLoss()\n",
        "            #     true_loss = xe(logits, y)\n",
        "            #     print('approx {:>3.2f}, true {:>3.2f}, diff {:>3.4f}'.format(\n",
        "            #       loss.data, true_loss.data, true_loss.data - loss.data))\n",
        "\n",
        "            # Update parameters\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip) # reduce exploding grad\n",
        "            optimizer.step()\n",
        "\n",
        "            # Save loss.\n",
        "            losses['train'].append(loss.cpu().data)\n",
        "            print_every = 500\n",
        "            if step % print_every == 0:\n",
        "                avg_loss = sum(losses['train'][-print_every:]) / print_every\n",
        "                t1 = time.time()\n",
        "                steps_per_second = print_every / (t1 - t0)\n",
        "                print('| epoch {} | step {}/{} | loss {:.4f} | lr {:.5f} | '\n",
        "                    'ngrams/sec {:.1f} | eta {}h{}m{}s'.format(\n",
        "                    epoch, step, num_steps, avg_loss, lr,\n",
        "                    steps_per_second * batch_size,\n",
        "                    *clock_time((num_steps - step) / steps_per_second)))\n",
        "                t0 = time.time()\n",
        "            \n",
        "        print('Evaluating on validation set...')\n",
        "        val_loss = evaluate(val_data, model, criterion)\n",
        "        losses['val'].append(val_loss)\n",
        "        print('-' * 89)\n",
        "        print('| end of epoch {:3d} | time {:5.2f}s | valid loss {:5.2f} | valid ppl {:8.2f}'.format(\n",
        "            epoch, (time.time() - epoch_start_time), val_loss, torch.exp(val_loss)))\n",
        "        print('-' * 89)\n",
        "\n",
        "        if not best_val_loss or val_loss < best_val_loss:\n",
        "            stop_counter = 0 # reset counter\n",
        "            best_val_loss = val_loss\n",
        "            print('| saving current state of model ...')\n",
        "            torch.save(model.state_dict(), 'checkpoint.pth')\n",
        "            #=== download checkpoint file\n",
        "            # files.download('checkpoint.pth')\n",
        "        elif val_loss < best_val_loss and val_loss < losses['val'][-2] and val_loss < torch.mean(torch.stack(losses['val'])): # curr loss less than best loss and previous loss\n",
        "            stop_counter += 1\n",
        "            if stop_counter >= 10:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "except KeyboardInterrupt:\n",
        "    print('-' * 89)\n",
        "    print('Exiting from training early')\n",
        "    \n",
        "# write_losses(losses['train'], args.log_dir, name='train-losses')\n",
        "# write_losses(losses['val'], args.log_dir, name='val-losses')\n",
        "\n",
        "print('Evaluating on test set...')\n",
        "test_loss = evaluate(test_data, model, criterion)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
        "    test_loss, torch.exp(test_loss)))\n",
        "print('=' * 89)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "| epoch 1 | step 500/2080 | loss 8.5133 | lr 0.00100 | ngrams/sec 47834.6 | eta 0h0m33s\n",
            "| epoch 1 | step 1000/2080 | loss 8.2916 | lr 0.00100 | ngrams/sec 48417.8 | eta 0h0m22s\n",
            "| epoch 1 | step 1500/2080 | loss 8.2205 | lr 0.00100 | ngrams/sec 47742.1 | eta 0h0m12s\n",
            "| epoch 1 | step 2000/2080 | loss 8.1656 | lr 0.00100 | ngrams/sec 47068.0 | eta 0h0m1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 110/209 [00:00<00:00, 1090.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 209/209 [00:00<00:00, 299.04it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time 44.29s | valid loss  6.93 | valid ppl  1025.47\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 2 | step 500/2080 | loss 8.0339 | lr 0.00100 | ngrams/sec 35958.0 | eta 0h0m43s\n",
            "| epoch 2 | step 1000/2080 | loss 8.0460 | lr 0.00100 | ngrams/sec 45688.2 | eta 0h0m23s\n",
            "| epoch 2 | step 1500/2080 | loss 8.0304 | lr 0.00100 | ngrams/sec 45074.6 | eta 0h0m12s\n",
            "| epoch 2 | step 2000/2080 | loss 8.0210 | lr 0.00100 | ngrams/sec 44167.1 | eta 0h0m1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 109/209 [00:00<00:00, 1038.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 209/209 [00:00<00:00, 267.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time 46.79s | valid loss  6.78 | valid ppl   878.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 3 | step 500/2080 | loss 7.9014 | lr 0.00100 | ngrams/sec 33465.2 | eta 0h0m47s\n",
            "| epoch 3 | step 1000/2080 | loss 7.9278 | lr 0.00100 | ngrams/sec 44274.4 | eta 0h0m24s\n",
            "| epoch 3 | step 1500/2080 | loss 7.9397 | lr 0.00100 | ngrams/sec 44795.8 | eta 0h0m12s\n",
            "| epoch 3 | step 2000/2080 | loss 7.9277 | lr 0.00100 | ngrams/sec 44998.9 | eta 0h0m1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 110/209 [00:00<00:00, 1064.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 209/209 [00:00<00:00, 281.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time 47.67s | valid loss  6.70 | valid ppl   808.82\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 4 | step 500/2080 | loss 7.7989 | lr 0.00100 | ngrams/sec 34695.8 | eta 0h0m45s\n",
            "| epoch 4 | step 1000/2080 | loss 7.8350 | lr 0.00100 | ngrams/sec 44520.6 | eta 0h0m24s\n",
            "| epoch 4 | step 1500/2080 | loss 7.8514 | lr 0.00100 | ngrams/sec 44216.6 | eta 0h0m13s\n",
            "| epoch 4 | step 2000/2080 | loss 7.8397 | lr 0.00100 | ngrams/sec 44233.1 | eta 0h0m1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 109/209 [00:00<00:00, 1063.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 209/209 [00:00<00:00, 272.71it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time 47.61s | valid loss  6.65 | valid ppl   775.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 5 | step 500/2080 | loss 7.7226 | lr 0.00100 | ngrams/sec 34300.1 | eta 0h0m46s\n",
            "| epoch 5 | step 1000/2080 | loss 7.7682 | lr 0.00100 | ngrams/sec 44549.2 | eta 0h0m24s\n",
            "| epoch 5 | step 1500/2080 | loss 7.7910 | lr 0.00100 | ngrams/sec 44566.2 | eta 0h0m13s\n",
            "| epoch 5 | step 2000/2080 | loss 7.7998 | lr 0.00100 | ngrams/sec 44508.3 | eta 0h0m1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 109/209 [00:00<00:00, 1083.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 209/209 [00:00<00:00, 275.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time 47.52s | valid loss  6.50 | valid ppl   663.71\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 6 | step 500/2080 | loss 7.6654 | lr 0.00100 | ngrams/sec 34380.7 | eta 0h0m45s\n",
            "| epoch 6 | step 1000/2080 | loss 7.7023 | lr 0.00100 | ngrams/sec 44449.1 | eta 0h0m24s\n",
            "| epoch 6 | step 1500/2080 | loss 7.7369 | lr 0.00100 | ngrams/sec 44408.7 | eta 0h0m13s\n",
            "| epoch 6 | step 2000/2080 | loss 7.7585 | lr 0.00100 | ngrams/sec 44387.0 | eta 0h0m1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 109/209 [00:00<00:00, 1079.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 209/209 [00:00<00:00, 273.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time 47.61s | valid loss  6.42 | valid ppl   614.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 7 | step 500/2080 | loss 7.6114 | lr 0.00100 | ngrams/sec 34303.2 | eta 0h0m46s\n",
            "| epoch 7 | step 1000/2080 | loss 7.6465 | lr 0.00100 | ngrams/sec 44332.3 | eta 0h0m24s\n",
            "| epoch 7 | step 1500/2080 | loss 7.7014 | lr 0.00100 | ngrams/sec 44346.1 | eta 0h0m13s\n",
            "| epoch 7 | step 2000/2080 | loss 7.7013 | lr 0.00100 | ngrams/sec 44371.0 | eta 0h0m1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 109/209 [00:00<00:00, 1065.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 209/209 [00:00<00:00, 273.92it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time 47.69s | valid loss  6.38 | valid ppl   592.28\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 8 | step 500/2080 | loss 7.5561 | lr 0.00100 | ngrams/sec 34266.0 | eta 0h0m46s\n",
            "| epoch 8 | step 1000/2080 | loss 7.5883 | lr 0.00100 | ngrams/sec 44380.2 | eta 0h0m24s\n",
            "| epoch 8 | step 1500/2080 | loss 7.6093 | lr 0.00100 | ngrams/sec 44358.1 | eta 0h0m13s\n",
            "| epoch 8 | step 2000/2080 | loss 7.6388 | lr 0.00100 | ngrams/sec 44365.5 | eta 0h0m1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 109/209 [00:00<00:00, 1086.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 209/209 [00:00<00:00, 274.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time 47.67s | valid loss  6.49 | valid ppl   657.19\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 9 | step 500/2080 | loss 7.5129 | lr 0.00100 | ngrams/sec 34644.2 | eta 0h0m45s\n",
            "| epoch 9 | step 1000/2080 | loss 7.5634 | lr 0.00100 | ngrams/sec 44369.6 | eta 0h0m24s\n",
            "| epoch 9 | step 1500/2080 | loss 7.6036 | lr 0.00100 | ngrams/sec 44330.4 | eta 0h0m13s\n",
            "| epoch 9 | step 2000/2080 | loss 7.6211 | lr 0.00100 | ngrams/sec 44345.2 | eta 0h0m1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 110/209 [00:00<00:00, 1042.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 209/209 [00:00<00:00, 275.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time 47.65s | valid loss  6.36 | valid ppl   577.71\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 10 | step 500/2080 | loss 7.4822 | lr 0.00100 | ngrams/sec 34245.0 | eta 0h0m46s\n",
            "| epoch 10 | step 1000/2080 | loss 7.5321 | lr 0.00100 | ngrams/sec 44284.7 | eta 0h0m24s\n",
            "| epoch 10 | step 1500/2080 | loss 7.5639 | lr 0.00100 | ngrams/sec 44312.8 | eta 0h0m13s\n",
            "| epoch 10 | step 2000/2080 | loss 7.5889 | lr 0.00100 | ngrams/sec 44347.3 | eta 0h0m1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 109/209 [00:00<00:00, 1071.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating on validation set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 209/209 [00:00<00:00, 273.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time 47.73s | valid loss  6.31 | valid ppl   552.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 11 | step 500/2080 | loss 7.4494 | lr 0.00100 | ngrams/sec 34235.5 | eta 0h0m46s\n",
            "| epoch 11 | step 1000/2080 | loss 7.4788 | lr 0.00100 | ngrams/sec 44332.0 | eta 0h0m24s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 46%|████▋     | 110/237 [00:00<00:00, 1060.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "Exiting from training early\n",
            "Evaluating on test set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 237/237 [00:00<00:00, 251.06it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=========================================================================================\n",
            "| End of training | test loss  6.25 | test ppl   515.92\n",
            "=========================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "jUqz8keSi6Mi",
        "outputId": "4f62017d-048d-4932-c8be-86c88ee65826"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('checkpoint.pth')\n",
        "!cp \"checkpoint.pth\" \"gdrive/MyDrive/checkpoint.pth\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e97a0f66-ef8f-4d9a-98fe-72f08c2753b2\", \"checkpoint.pth\", 47497733)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3ttFGoKoBR4"
      },
      "source": [
        "# Generate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVk-BCi3oCqJ"
      },
      "source": [
        "!cp \"gdrive/MyDrive/checkpoint.pth\" \"checkpoint.pth\" "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dbo0u8vePGHv",
        "outputId": "7db51c53-8ba4-4e1b-fa38-6363837ea311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "source": [
        "import torch \n",
        "# Model parameters.\n",
        "class Args:\n",
        "    data = 'gdrive/MyDrive/wikitext-2'\n",
        "    checkpoint = 'checkpoint.pth'\n",
        "    outf = 'generated.txt'\n",
        "    words = 1000\n",
        "    seed = 42\n",
        "    cuda = True\n",
        "    temperature = 1.0 # temperature - higher will increase diversity\n",
        "    log_interval = 100 # reporting interval\n",
        "    num_samples = 10\n",
        "args = Args()\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "    if not args.cuda:\n",
        "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "\n",
        "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "\n",
        "if args.temperature < 1e-3:\n",
        "    parser.error(\"--temperature has to be greater or equal 1e-3\")\n",
        "\n",
        "model.load_state_dict(torch.load(args.checkpoint))\n",
        "print(model)\n",
        "model.eval()\n",
        "\n",
        "input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
        "\n",
        "glue = ''\n",
        "start = None\n",
        "with open(args.outf, 'w') as outf:\n",
        "    for i in range(args.num_samples):\n",
        "        output = model(input)\n",
        "        word_weights = output.squeeze().div(args.temperature).exp().cpu()\n",
        "        # if args.no_unk:\n",
        "        #     word_weights[corpus.dictionary.w2i[unk]] = 0\n",
        "        # word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "        # word_idx = word_idx.data[0]\n",
        "        # word = corpus.dictionary.i2w[word_idx]\n",
        "\n",
        "        # ids.append(word_idx)\n",
        "        # input = Variable(torch.LongTensor(ids[-model.order:]).unsqueeze(0))\n",
        "        input = input.cuda() if cuda else input\n",
        "        if word is \"<sos>\": # ignore start of sentence predictns\n",
        "            continue\n",
        "        elif word is \"<eos>\":\n",
        "            outf.write('\\n')\n",
        "        else:\n",
        "            outf.write(word + glue)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print('| Generated {}/{} words'.format(i, args.num_samples))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FNNModel(\n",
            "  (embeddings): Embedding(28912, 200)\n",
            "  (linear1): Linear(in_features=1400, out_features=200, bias=True)\n",
            "  (linear2): Linear(in_features=200, out_features=28912, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c9c7bbb09b2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mword_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_unk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-ef19755687f0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mhidden_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# hidden_output = self.dropout(hidden_output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 1400]' is invalid for input of size 200"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzQ6XBeFUir3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}